{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    " \n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score, classification_report, plot_confusion_matrix, auc\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "def accuracy(y, y_hat):\n",
    "    y_y_hat = list(zip(y, y_hat))\n",
    "    tp = sum([1 for i in y_y_hat if i[0] == 1 and i[1] == 1])\n",
    "    tn = sum([1 for i in y_y_hat if i[0] == 0 and i[1] == 0])\n",
    "    return (tp + tn) / float(len(y_y_hat))\n",
    "\n",
    "def f1(y, y_hat):\n",
    "    precision_score = precision(y, y_hat)\n",
    "    recall_score = recall(y, y_hat)\n",
    "    numerator = precision_score * recall_score\n",
    "    denominator = precision_score + recall_score\n",
    "    return 2 * (numerator / denominator)\n",
    "\n",
    "def precision(y, y_hat):\n",
    "    y_y_hat = list(zip(y, y_hat))\n",
    "    tp = sum([1 for i in y_y_hat if i[0] == 1 and i[1] == 1])\n",
    "    fp = sum([1 for i in y_y_hat if i[0] == 0 and i[1] == 1])\n",
    "    return tp / float(tp + fp)\n",
    "\n",
    "def recall(y, y_hat):\n",
    "    # Your code here\n",
    "    y_y_hat = list(zip(y, y_hat))\n",
    "    tp = sum([1 for i in y_y_hat if i[0] == 1 and i[1] == 1])\n",
    "    fn = sum([1 for i in y_y_hat if i[0] == 1 and i[1] == 0])\n",
    "    return tp / float(tp + fn)\n",
    "\n",
    "def get_metrics(y_tr, y_tt, y_pred_tr, y_pred_tt, model):\n",
    "    cnf = confusion_matrix(y_tt, y_pred_tt)\n",
    "    print('Training Accuracy: ', accuracy(y_tr, y_pred_tr))\n",
    "    print('Testing Accuracy: ', accuracy(y_tt, y_pred_tt))\n",
    "    print('Training F1 Score: ', f1(y_tr, y_pred_tr))\n",
    "    print('Testing F1 Score: ', f1(y_tt, y_pred_tt))\n",
    "    print('Training AUC Score: {}'.format(roc_auc_score(y_tr, model.predict_proba(X_tr)[:,1])))\n",
    "    print('Testing AUC Score: {}'.format(roc_auc_score(y_tt, model.predict_proba(X_tt)[:,1])))\n",
    "    print('Training Recall Score: ', recall(y_tr, y_pred_tr))\n",
    "    print('Testing Recall Score: ', recall(y_tt, y_pred_tt))\n",
    "    print('Training Precision Score: ', precision(y_tr, y_pred_tr))\n",
    "    print('Testing Precision Score: ', precision(y_tt, y_pred_tt))\n",
    "    print('')\n",
    "    print(\"Training Classification Report: \")\n",
    "    print(classification_report(y_tr, y_pred_tr))\n",
    "    print(\"\")\n",
    "    print(\"Testing Classification Report: \")\n",
    "    print(classification_report(y_tt, y_pred_tt))\n",
    "    group_names = ['TN','FP','FN','TP']\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in cnf.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in cnf.flatten()/np.sum(cnf)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cnf, annot=labels, fmt='', cmap='Blues', annot_kws={'size':16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}